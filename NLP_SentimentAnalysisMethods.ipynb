{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-SentimentAnalysisMethods.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9OdFxb11UqR"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtEdhTi90z65"
      },
      "source": [
        "This notebook is an attempt to implement sentiment analysis using different methods\n",
        "\n",
        "Starting with methods like Logistic Regression, Latent Dirilecht Analysis, Naive Baiyes etc\n",
        "\n",
        "We will be using twitter datasets from NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXVGEcYn1eKu"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBXjY69b0uv2"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import twitter_samples, stopwords\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import re\n",
        "import os  \n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHnejmmi1tJk"
      },
      "source": [
        "# Datasets and Few more Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXCY3jDr1sBk",
        "outputId": "c7f6dcf2-ce76-41eb-9112-c45620cfe4e2"
      },
      "source": [
        "# Download the twitter dataset. This will be the dataset that will be used\n",
        "nltk.download('twitter_samples')\n",
        "\n",
        "# Download the english stopwords that will be removed from the tweets during preprocessing\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_VwOOmHCnfk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eeXANCnCoLQ"
      },
      "source": [
        "# Get the positive and negative tweets from twitter_samples. These are of type list\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QQ-ChsIC0OG",
        "outputId": "dcf26b17-92e2-40f2-e83f-43802c979b14"
      },
      "source": [
        "# logging the type and lengths\n",
        "type(all_positive_tweets), len(all_positive_tweets), len(all_negative_tweets)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 5000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC0yd4KYDgWn"
      },
      "source": [
        " Let's take the last 1000 tweets as the test values for both positive and negative tweets.  \n",
        " That will leave the first 4000 tweets as the training data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTH_9rRaDDD2"
      },
      "source": [
        "# Separating positive tweets\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "\n",
        "# separating negative tweets\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "# Concatenating the positive and negative tweets to form the final test and train datasets\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "# Assigning labels \n",
        "# 1 = positive tweet and \n",
        "# 0 = negative tweet\n",
        "train_y = [1]*len(train_pos) + [0]*len(train_neg)\n",
        "test_y = [1]*len(test_pos) + [0]*len(test_neg)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6RRbuOoD09S",
        "outputId": "80eaaf2a-2614-4353-bfe2-aa7d5b26faf6"
      },
      "source": [
        "# Showing the final lengths of train and test datasets\n",
        "len(train_x), len(test_x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 2000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R6AYThhEQNb",
        "outputId": "36f674d2-7801-4cf4-d4f3-a905cc7ecf46"
      },
      "source": [
        "# Showing few positive and negative tweets\n",
        "print(train_x[:5])\n",
        "print(train_x[-5:])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)', '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!', '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!', '@97sides CONGRATS :)', 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days']\n",
            "['Amelia didnt stalk my twitter :(', 'oh, i missed the broadcast. : (', \"i really can't stream on melon i feel useless :-(\", 'I need to stop looking at old soccer pictures :(', 'Got an interview for the job that I want but they rang me Tuesday for the interview on Thursday but in on holiday :(']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjeezq2mMJID"
      },
      "source": [
        "# Text Preparing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtoNCB7jMbem"
      },
      "source": [
        "All tweets should be removed of stopwords, urls, hashtags, tweet_ats, stock market tickers converted into tokens\n",
        "\n",
        "Sequence of steps for preparation:\n",
        "\n",
        "1.   remove urls in tweets\n",
        "2.   Remove # and @ symbols\n",
        "3.   Remove stopwords\n",
        "4.   Tokenize the tweet\n",
        "5.   Stem the words in the tweet\n",
        "\n",
        "**Note**: Stemming gets the words to the root form of the word (need not end up as a proper word in the language like lemmatization would result in)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vozKZvWMLxF"
      },
      "source": [
        "def process_tweet(tweet):\n",
        "  # Getting rid of urls in the tweet\n",
        "  # Below regular expression removes http https links including any with port numbers\n",
        "  tweet = re.sub(r'http[s][:\\/\\w]*', '', tweet)\n",
        "\n",
        "  # Getting rid of @, we will still retain who the tweet is being addressed to by just removing the symbol\n",
        "  tweet = re.sub(r'@', '', tweet)\n",
        "\n",
        "  # Getting rid of # symbol, retaining the hashtag name\n",
        "  tweet = re.sub(r'#', '', tweet)\n",
        "\n",
        "  # Get the list of stopwords from nltk \n",
        "  stopwords_list = set(stopwords.words('english'))\n",
        "  #Let's print the stopwords as FYI\n",
        "  #print(\"stopwords =\", stopwords_list)\n",
        "\n",
        "  # Get a Tokenizer instance\n",
        "  tokenizer = TweetTokenizer(preserve_case=False, strip_handles=False, reduce_len=False)\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "  # The tokens generated will have stopwords and words that need to be stemmed\n",
        "  # Doing both in the next step\n",
        "\n",
        "  # Initialize a stemmer\n",
        "  stemmer = PorterStemmer() \n",
        "  \n",
        "  # stem the token if it is not a stopword and it is not a punctuation\n",
        "  clean_tweet=[stemmer.stem(token) for token in tokens if token not in stopwords_list and token not in string.punctuation ]\n",
        "  \n",
        "  return clean_tweet\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fyp8rnwMD1P"
      },
      "source": [
        "# Method 1: Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLtLxdFoU8Ms"
      },
      "source": [
        "## Preparation for Feature Extraction:\n",
        "For every word, find the number of times it has been used in a positive tweet and number of times it has been used in a negative tweet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0j-1AE4L-21"
      },
      "source": [
        "def build_frequencies(tweets, labels):\n",
        "  '''\n",
        "  Function to create a list of tuples, each tuple of the form (token, sentiment)\n",
        "\n",
        "  tweets: list of tweets\n",
        "  labels: list of labels if it is positive of negative\n",
        "  '''\n",
        "  # Using a defaultdict so that in case a key is unavailable, it will return 0 \n",
        "  # and it will also help in incrementing the frequencies\n",
        "  freq_list = defaultdict()\n",
        "  \n",
        "  # Go through each tweet and label\n",
        "  for tweet, label in zip(tweets, labels):\n",
        "    # get tokens from the tweet\n",
        "    tokens = process_tweet(tweet)\n",
        "    \n",
        "    # go through each token and increment the freq_list\n",
        "    for token in tokens:\n",
        "      freq_list[(token, label)] = freq_list.get((token, label),0) + 1\n",
        "\n",
        "  return freq_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL-9oP4_bO-s"
      },
      "source": [
        "## Extracting Features for LR\n",
        "We will have two features for LR, for a given tweet, we will get the frequencies for each token used in a positive context and negative context\n",
        "\n",
        "```\n",
        "tweet1 Features = sum of positive_freq of words in tweet1, sum of negative_freq of words in tweet1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynl1v92xbPba"
      },
      "source": [
        "def extract_features(tweets, frequencies):\n",
        "  '''\n",
        "  \n",
        "  tweets = list of tweets\n",
        "  frequencies = resulting dictionary from the function build_frequencies\n",
        "  '''\n",
        "  feature_list = []\n",
        "  for tweet in tweets:\n",
        "    # Get the tokens from the tweet\n",
        "    tokens = process_tweet(tweet)\n",
        "\n",
        "    # define the features array. \n",
        "    # index 0 = positive sentiment\n",
        "    # index 1 = negative sentiment\n",
        "    features = np.zeros((2,))\n",
        "\n",
        "    #go through the tokens and get the sum of positive and negative freqs\n",
        "    for token in tokens:\n",
        "      # add the token as a positive sentiment to the positive sentiment feature\n",
        "      features[0] += frequencies.get((token, 1),0)\n",
        "\n",
        "      # add the token as a negative sentiment to the negative sentiment feature\n",
        "      features[1] += frequencies.get((token, 0),0)\n",
        "    feature_list.append(features)\n",
        "\n",
        "  return feature_list\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBcL_nm4syla",
        "outputId": "e575bb07-7a22-4561-fc68-4457dd3689a7"
      },
      "source": [
        "print(\"stopwords =\", set(stopwords.words('english')))\n",
        "# get the frequencies from the training dataset\n",
        "frequencies = build_frequencies(tweets = train_x, labels = train_y)\n",
        "\n",
        "# get the features for training\n",
        "training_features = extract_features(tweets = train_x, frequencies = frequencies)\n",
        "\n",
        "# get the features for testing\n",
        "testing_features = extract_features(tweets = test_x, frequencies = frequencies)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopwords = {'your', 'doesn', 'a', 'more', 'now', 'mustn', 'yourself', 'they', 'their', 'there', 'once', 'being', 'all', 'those', 'into', 'no', 'wasn', 'to', 'out', 'be', 'any', 'too', 'ain', 'again', 'having', 'weren', 'which', 'been', 'such', 'same', 'theirs', 'by', \"wouldn't\", 't', 'below', 'myself', \"shan't\", 'am', 'mightn', \"mightn't\", 'each', 'with', 'and', 'on', \"you've\", 'about', 'should', 'for', 'here', 'then', 'most', 'has', 'itself', 'through', 'd', \"mustn't\", 'm', 'shouldn', 'during', \"you'll\", 'do', 'just', 'didn', 'my', 'yourselves', 'what', 'were', 'couldn', \"should've\", 'against', 'y', 'ours', 'very', \"hasn't\", 'that', 'i', 'its', 'them', 'aren', 'we', \"isn't\", \"wasn't\", 'she', 'themselves', \"you're\", \"weren't\", \"don't\", 'don', 'hasn', 'these', 'had', 'hers', 'under', \"aren't\", 'o', 'are', \"shouldn't\", 'or', 'an', 'did', 'shan', 'needn', 'yours', \"won't\", 'the', 'ourselves', 'before', 'further', 'but', 'up', 'when', 'from', 'how', 'he', 'why', \"didn't\", 'haven', 'while', 'both', 'if', 'hadn', \"it's\", 'over', 'who', \"couldn't\", 'can', 'have', \"she's\", 'will', \"that'll\", 'was', 'her', 'because', 'some', 'me', 've', 'so', 'where', 'than', 'above', 'won', 'ma', \"hadn't\", 'himself', 'until', 'it', 'at', \"doesn't\", 'not', \"needn't\", 'between', 'after', 'll', 'own', 'nor', \"haven't\", 'does', 'whom', 'is', 'down', 'few', 'only', 's', 'isn', 'in', 'off', 'other', 'wouldn', 'him', \"you'd\", 'doing', 'as', 'of', 'herself', 'his', 'our', 'this', 'you', 're'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVy5ONRewciP",
        "outputId": "deeb73d0-ec26-4883-8b08-3dc7f47ae459"
      },
      "source": [
        "print(\"train data =\", train_x[0])\n",
        "\n",
        "print(\"processed tweet =\", process_tweet(train_x[0]))\n",
        "\n",
        "print(\"training_features:\", training_features[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data = #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
            "processed tweet = ['followfriday', 'france_int', 'pkuchli', '57', 'milipol_pari', 'top', 'engag', 'member', 'commun', 'week', ':)']\n",
            "training_features: [3138.   61.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ljV8aBFzeaR"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knuDbgT6swtr"
      },
      "source": [
        "## Building LR Model\n",
        "\n",
        "We will implement LR model using Tensorflow as a single unit Dense layer with sigmoid activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBjsdQrP0TFa"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KJYBF2wt3RT"
      },
      "source": [
        "def lr_model(batch_size=10):\n",
        "  '''\n",
        "  function to build logistic regression model using Tensorflow\n",
        "  '''\n",
        "  input = Input(shape = (2,), batch_size = batch_size, name='input')\n",
        "  x = Dense(1, activation='sigmoid', name='dense')(input)\n",
        "\n",
        "  model = Model(inputs = input, outputs = x, name='lr_model')\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p47oa7DqvpjG",
        "outputId": "549c5c17-aaa1-462f-8e13-ddcd0581932b"
      },
      "source": [
        "lr_model = lr_model()\n",
        "lr_model.compile(optimizer='adam'\n",
        "                  , loss='binary_crossentropy'\n",
        "                  , metrics = ['accuracy']\n",
        "                 )\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"lr_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(10, 2)]                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (10, 1)                   3         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMuszh3DAMmS",
        "outputId": "934e9df9-6b47-4d5b-fe9b-be8aaa86a4be"
      },
      "source": [
        "len(training_features)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxT9-suQAPTx"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKYoiOWQwKtp",
        "outputId": "81d9c015-cad5-489d-dc4d-4eed5d531936"
      },
      "source": [
        "metrics = lr_model.fit(x=np.array(training_features)\n",
        "             , y = np.array(train_y)\n",
        "             , epochs = 30\n",
        "             , shuffle=True\n",
        "             , validation_split=0.1\n",
        "\n",
        "             )\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Model was constructed with shape (10, 2) for input KerasTensor(type_spec=TensorSpec(shape=(10, 2), dtype=tf.float32, name='input'), name='input', description=\"created by layer 'input'\"), but it was called on an input with incompatible shape (32, 2).\n",
            "WARNING:tensorflow:Model was constructed with shape (10, 2) for input KerasTensor(type_spec=TensorSpec(shape=(10, 2), dtype=tf.float32, name='input'), name='input', description=\"created by layer 'input'\"), but it was called on an input with incompatible shape (32, 2).\n",
            "208/225 [==========================>...] - ETA: 0s - loss: 52.5081 - accuracy: 0.7462WARNING:tensorflow:Model was constructed with shape (10, 2) for input KerasTensor(type_spec=TensorSpec(shape=(10, 2), dtype=tf.float32, name='input'), name='input', description=\"created by layer 'input'\"), but it was called on an input with incompatible shape (32, 2).\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 48.6758 - accuracy: 0.7618 - val_loss: 3.0758 - val_accuracy: 0.9137\n",
            "Epoch 2/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 1.0620 - accuracy: 0.9674 - val_loss: 1.0216 - val_accuracy: 0.9488\n",
            "Epoch 3/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.9824 - val_loss: 0.4620 - val_accuracy: 0.9688\n",
            "Epoch 4/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9900 - val_loss: 0.1701 - val_accuracy: 0.9837\n",
            "Epoch 5/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9932 - val_loss: 0.0834 - val_accuracy: 0.9887\n",
            "Epoch 6/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9950 - val_loss: 0.0434 - val_accuracy: 0.9937\n",
            "Epoch 7/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9939 - val_loss: 0.0297 - val_accuracy: 0.9937\n",
            "Epoch 8/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9940 - val_loss: 0.0207 - val_accuracy: 0.9950\n",
            "Epoch 9/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9936 - val_loss: 0.0183 - val_accuracy: 0.9950\n",
            "Epoch 10/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9939 - val_loss: 0.0232 - val_accuracy: 0.9950\n",
            "Epoch 11/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9936 - val_loss: 0.0243 - val_accuracy: 0.9937\n",
            "Epoch 12/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9933 - val_loss: 0.0226 - val_accuracy: 0.9950\n",
            "Epoch 13/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9940 - val_loss: 0.0163 - val_accuracy: 0.9950\n",
            "Epoch 14/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9931 - val_loss: 0.0177 - val_accuracy: 0.9950\n",
            "Epoch 15/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9936 - val_loss: 0.0304 - val_accuracy: 0.9937\n",
            "Epoch 16/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9937 - val_loss: 0.0208 - val_accuracy: 0.9937\n",
            "Epoch 17/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9942 - val_loss: 0.0215 - val_accuracy: 0.9937\n",
            "Epoch 18/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0585 - accuracy: 0.9943 - val_loss: 0.0169 - val_accuracy: 0.9950\n",
            "Epoch 19/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9942 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
            "Epoch 20/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9947 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9940 - val_loss: 0.0284 - val_accuracy: 0.9887\n",
            "Epoch 22/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.9951 - val_loss: 0.0149 - val_accuracy: 0.9937\n",
            "Epoch 23/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9933 - val_loss: 0.0214 - val_accuracy: 0.9912\n",
            "Epoch 24/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9949 - val_loss: 0.0190 - val_accuracy: 0.9925\n",
            "Epoch 25/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9942 - val_loss: 0.0179 - val_accuracy: 0.9925\n",
            "Epoch 26/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 0.9936 - val_loss: 0.0459 - val_accuracy: 0.9825\n",
            "Epoch 27/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9937 - val_loss: 0.0111 - val_accuracy: 0.9962\n",
            "Epoch 28/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9929 - val_loss: 0.0215 - val_accuracy: 0.9912\n",
            "Epoch 29/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9939 - val_loss: 0.0246 - val_accuracy: 0.9875\n",
            "Epoch 30/30\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9926 - val_loss: 0.0169 - val_accuracy: 0.9925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "uGamaMF70iE7",
        "outputId": "6fb30511-c2cd-489e-92cb-07cf5b1a7ea8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(metrics.history['loss'], label='train')\n",
        "plt.plot(metrics.history['val_loss'], label='test')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(metrics.history['accuracy'], label='train')\n",
        "plt.plot(metrics.history['val_accuracy'], label='test')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f976d8cd9d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfWUkUl_Dpmd"
      },
      "source": [
        "### Predictions and Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk9yACFBDQ32",
        "outputId": "f4b5d833-541b-4ed8-96dd-d94a2b574a93"
      },
      "source": [
        "y_pred = lr_model.predict(np.array(testing_features))\n",
        "\n",
        "confusion_matrix = tf.math.confusion_matrix(test_y, y_pred, num_classes=2)\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1000    0]\n",
            " [ 305  695]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuliMcO6EQW-",
        "outputId": "d1db9317-a5bb-4114-ef5b-a95aba23d8df"
      },
      "source": [
        "y_pred[:5]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        ],\n",
              "       [1.        ],\n",
              "       [0.9999888 ],\n",
              "       [1.        ],\n",
              "       [0.99979305]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pb-dWoSEqV2"
      },
      "source": [
        "# Method 2: Linear Discrimant Analysis (LDA)\n",
        "\n",
        "In LDA we find the centroids of each class of tweets, use the gap between the centroids as the differentiating factor between the classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRhfa8xHEkvh"
      },
      "source": [
        "# we need to represent the tweets as vectors, we do this using sklearn's TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tweetVectorizer = TfidfVectorizer(tokenizer = process_tweet\n",
        "                               , stop_words=list(stopwords.words('english'))\n",
        "                               )\n",
        "\n",
        "# Obtaining the vector representations of the tweets\n",
        "tweetTfidf = tweetVectorizer.fit_transform(train_x)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MgZBiMfKObC",
        "outputId": "8987fd4d-3ecf-4007-94f9-09a852f1a3ab"
      },
      "source": [
        "type(tweetTfidf), tweetTfidf.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(scipy.sparse.csr.csr_matrix, (8000, 16652))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y41qp_bMWe6"
      },
      "source": [
        "tweetTfidf = tweetTfidf.toarray()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4qMf48XKrvt"
      },
      "source": [
        "## Calculating the centroids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThtreTtJKXu3",
        "outputId": "bd185b38-6909-4a1a-9f16-ff0978ddcef1"
      },
      "source": [
        "# create a boolean mask to use to calculate the mean\n",
        "positive_mask = [y == 1 for y in train_y]\n",
        "print(\"length of mask = \", len(positive_mask))\n",
        "\n",
        "\n",
        "# calculating the positive centroid\n",
        "positive_centroid = tweetTfidf[positive_mask].mean(axis=0)\n",
        "print(\"positive centroid = \", positive_centroid.shape, \"\\n\", positive_centroid)\n",
        "\n",
        "# calculating the negative centroid using a negation of the positive mask\n",
        "negative_centroid = tweetTfidf[[~val for val in positive_mask]].mean(axis=0)\n",
        "print(\"negative centroid =\", negative_centroid.shape, \"\\n\", negative_centroid)\n",
        "\n",
        "# Finding the vector connecting the two centroids\n",
        "difference = positive_centroid - negative_centroid\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of mask =  8000\n",
            "positive centroid =  (16652,) \n",
            " [7.10403873e-05 8.27011206e-05 3.69501277e-04 ... 0.00000000e+00\n",
            " 0.00000000e+00 9.05286295e-05]\n",
            "negative centroid = (16652,) \n",
            " [0. 0. 0. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDqhniwUPEGM"
      },
      "source": [
        "## Testing\n",
        "Predictions are done by \n",
        "1. finding the projection of the tweets onto the  vector connecting the positive and negative centroids, \n",
        "2. scale the result between the range [0, 1], and \n",
        "3. use a threshold like 0.5 or 0.7 to get a binary output prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPGGQBWRM-fa",
        "outputId": "771fdf47-6eb8-45b6-d355-6a9febb7136f"
      },
      "source": [
        "# First we find the tfidfVector representation of the test data\n",
        "# since the output is a sparse matrix, it is converted to dense\n",
        "testTfidf = tweetVectorizer.transform(test_x).toarray()\n",
        "\n",
        "# Calculating the projection of the test data onto the difference vector\n",
        "testVectorProjection = np.dot(testTfidf, difference)\n",
        "\n",
        "print(\"projection shape and few samples = \", testVectorProjection.shape, \"\\n\", testVectorProjection[:5])\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "projection shape and few samples =  (2000,) \n",
            " [0.00981867 0.02888441 0.01515301 0.01238402 0.02374018]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nucbpVIOUFxc",
        "outputId": "13bf9a35-4495-4740-cb0c-a0c69528609a"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# instantiate the scaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "# Scale the prediction between 0 and 1\n",
        "scaled_y_pred = scaler.fit_transform(np.reshape(testVectorProjection, (-1, 1)))\n",
        "print(\"sample scaled projecion =\", scaled_y_pred[:5])\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample scaled projecion = [[0.70713655]\n",
            " [0.78168435]\n",
            " [0.72799405]\n",
            " [0.71716718]\n",
            " [0.76157019]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFHdIqOXLU2B"
      },
      "source": [
        "# Using threshold as 0.5 to\n",
        "y_pred = [int(y > 0.7) for y in scaled_y_pred ]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LWAzVn5XYmP"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w_YR48fWh-n",
        "outputId": "9adc733a-f4d8-4e50-b2e5-07f90f3b4bc0"
      },
      "source": [
        "confusion_matrix = tf.math.confusion_matrix(test_y, y_pred, num_classes=2)\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[992   8]\n",
            " [157 843]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64diFasMXhzZ"
      },
      "source": [
        "# Method 3: Naiive Bayes\n",
        "\n",
        "Naiive Bayes assumes that every word is independent of each other\n",
        "$$sentiment(tweet) = logprior * log(\\prod_i^N \\frac{p(positive|word)}{p(negative|word)})$$\n",
        "$$sentiment(tweet) = logprior * \\sum_i^N( log(p(positive|word)) - log(p(negative|word)) ) $$\n",
        "$$sentiment(tweet) = logprior * \\sum_i^N(likelihood(word)) $$\n",
        "\n",
        "where N = Number of words in a tweet\n",
        "\n",
        "First we calculate the logprior, i.e., log of the ratio probability of positive tweets to negative tweets. This will indicate the bias in the dataset, if any.\n",
        "\n",
        "$$P(D_{pos}) = \\frac{D_{pos}}{D}\\tag{1}$$\n",
        "\n",
        "$$P(D_{neg}) = \\frac{D_{neg}}{D}\\ $$\n",
        "\n",
        "where \n",
        "\n",
        "* $D_{pos}$ is the number of positive tweets\n",
        "* $D_{neg}$ is the number of negative tweets\n",
        "* $D$ is the total number of tweets\n",
        "\n",
        "$$ logprior = log(\\frac{P(D_{pos})}{P(D_{neg})})$$\n",
        "$$ logprior = log(\\frac{D_{pos}}{D_{neg}})$$\n",
        "$$ logprior = log(D_{pos})-log(D_{neg})$$\n",
        "\n",
        "Next we find the likelihood of a word in the vocabulary of being positive or negative setiment. \n",
        "1. probability of a word being a particular sentiment (using Laplacian smoothing to avoid log(0))\n",
        "2. likelihood of the word is the log of ratio of probabilities (positive to negative)\n",
        "\n",
        "$$ p(positive|word) = \\frac{freq(word\\_as\\_positive) + 1}{N_{pos} + V}$$\n",
        "$$ p(negative|word) = \\frac{freq(word\\_as\\_negative) + 1}{N_{neg} + V}$$\n",
        "\n",
        "$$ log\\_likelihood(word) = log(p(positive|word)) - log(p(negative|word)) $$\n",
        "\n",
        "where \n",
        "* V = vocabulary size\n",
        "* $N_{pos}$ = Total Number of positive words\n",
        "* $N_{neg}$ = Total number of negative words\n",
        "\n",
        "**In conclusion**, likelihood is \n",
        "* \\> (greater than) 1 if the word tends to be more positively used in the vocabulary\n",
        "* = 1 if the word is neutral\n",
        "* \\< (less than) 1 if the word tends to be more negatively used in the vocabulary\n",
        "\n",
        "**And **, log likelihood is\n",
        "* \\>(greater than) 0 if the word is positively used in the vocabulary\n",
        "* = 0 if the word is neutral\n",
        "* \\<(less than) 0 if the word tends to be more negatively used in the vocabulary\n",
        "\n",
        "\n",
        "The above steps are the training steps for Naiive Bayes model. The parameters of the model being\n",
        "1. logprior - float that signifies the bias within the dataset towards a sentiment\n",
        "2. log likelihood: dictionary of word and its likelihood of a sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac6Q_2Ofouu6"
      },
      "source": [
        "## Calculating Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cHnEJqUWjdy"
      },
      "source": [
        "\n",
        "def calculate_naiive_bayes_params(tweets, labels):\n",
        "  '''\n",
        "  Function to calculate the log prior and log likelihood for a Naiive Bayes model\n",
        "  tweets: list of tweets, i.e. training dataset\n",
        "  labels: list of 1-D labels that signify the sentiment of the tweets. This should be the same length as the tweets.\n",
        "          Assumption is positive sentiment = 1 and negative sentiment = 0\n",
        "\n",
        "  Returns: a tuple (float, dictionary)\n",
        "  log_prior: float, log prior of the training dataset provided\n",
        "  log_likelihood: dictionary, key = token and value = log likelihood of the token\n",
        "  '''\n",
        "  # Calculating logprior, total number of positive tweets / total number of negative tweets\n",
        "  # since positive tweet is represented as 1 and negative tweet is 0, we can put logprior as \n",
        "  log_prior = np.log(sum(labels)) - np.log(len(labels) - sum(labels))\n",
        "  print(\"logprior = \", log_prior)\n",
        "\n",
        "  # Next we are going to calculate the log likelihood of the words in the vocab\n",
        "\n",
        "  # First build the frequencies dictionary key= (token, sentiment) value = frequency\n",
        "  frequencies = build_frequencies(tweets, labels)\n",
        "\n",
        "  # We need to know the vocabulary length V, total number of positive words and negative words\n",
        "\n",
        "  # initialize a set for vocabulary\n",
        "  vocab = set()\n",
        "  # initialize the counts of positive and negative tokens\n",
        "  n_pos = n_neg = 0\n",
        "  # loop through the frequencies dictionary\n",
        "  for token, sentiment in frequencies.keys():\n",
        "    #add the token into the vocabulary set\n",
        "    # since it is a set, it avoids duplication\n",
        "    vocab.add(token)\n",
        "\n",
        "    # increment n_pos and n_neg based on sentiment of the token\n",
        "    if sentiment == 1: # positive sentiment\n",
        "      n_pos += 1\n",
        "    else: # negative sentiment\n",
        "      n_neg += 1\n",
        "  print(\"length of vocab =\", len(vocab))\n",
        "  print(\"total number of positive tokens =\", n_pos)\n",
        "  print(\"total number of negative tokens =\", n_neg)\n",
        "\n",
        "  # Going through the vocabulary to create log likehood dictionary\n",
        "  log_likelihood = defaultdict()\n",
        "\n",
        "  for token in vocab:\n",
        "    # Find the likelihood that the token is positive. Include Laplacian smoothing\n",
        "    likelihood_positive = (frequencies.get((token, 1),0) + 1)/(n_pos + len(vocab)) \n",
        "\n",
        "    # Find the likelihood that the token is negative. Include Laplacian smoothing\n",
        "    likelihood_negative = (frequencies.get((token, 0),0) + 1)/(n_neg + len(vocab))\n",
        "\n",
        "    # Find the log likelihood of the token\n",
        "    log_likelihood[token] = np.log(likelihood_positive) - np.log(likelihood_negative)\n",
        "  \n",
        "  return log_prior, log_likelihood\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRax_2_4vHhi"
      },
      "source": [
        "## Predicting Sentiments\n",
        "\n",
        "Given a test tweet, below steps will be followed to make a prediction using Naiive Bayes method\n",
        "1. Get the tokens from the tweet by calling process_tweet\n",
        "2. Find the log likelihood of each of the tokens using the dictionary from calculate_naiive_bayes_params function. If a token is not in the log_likelihood dictionary, assume that it is neutral\n",
        "3. Calculate the log likelihood of the test tweet using the formula: \n",
        "$$logprior + \\sum  log likelihood(tokens\\ in\\ the\\ test\\ tweet)$$\n",
        "4. If log likelihood of the test tweet is greater than zero, then the sentiment of the tweet is positive, else it is negative\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlJOb2ihw7s9",
        "outputId": "80edda92-9631-420a-9e52-69da9fd0b4fe"
      },
      "source": [
        "# Get the Naiive Bayes parameters\n",
        "log_prior, log_likelihood = calculate_naiive_bayes_params(train_x, train_y)\n",
        "\n",
        "# Initialize an empty list for the predictions\n",
        "y_pred = []\n",
        "\n",
        "# Go through each tweet in the testing dataset\n",
        "for tweet in test_x:\n",
        "  # Step 1: get the tokens from the tweet\n",
        "  tokens = process_tweet(tweet)\n",
        "\n",
        "  # Step 2 and 3: find sum of log likelihood of the tokens\n",
        "  tweet_log_likelihood = np.sum([log_likelihood.get(token,0) for token in tokens])\n",
        "\n",
        "  # Step 3: Calculate the sentiment value\n",
        "  sentiment = log_prior + tweet_log_likelihood\n",
        "\n",
        "  # Step 4: make final prediction\n",
        "  if (sentiment >0):\n",
        "    # Positive sentiment\n",
        "    y_pred.append(1)\n",
        "  else:\n",
        "    # negative sentiment\n",
        "    y_pred.append(0)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logprior =  0.0\n",
            "length of vocab = 16674\n",
            "total number of positive tokens = 10587\n",
            "total number of negative tokens = 8505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X50SopGqy2cr"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3XA6-wky3o2",
        "outputId": "d7aebe38-68cc-4eb4-c05b-87ea763a5512"
      },
      "source": [
        "confusion_matrix = tf.math.confusion_matrix(test_y, y_pred, num_classes=2)\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[995   5]\n",
            " [  8 992]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLB9OoV4zbuM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}