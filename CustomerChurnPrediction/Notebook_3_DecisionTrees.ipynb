{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]=\"notebook --no-browser\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_161/jre\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/spark-2.4.4-bin-hadoop2.7\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecommerce Churn Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the assignment is to build a model that predicts whether a person purchases an item after it has been added to the cart or not. Being a classification problem, you are expected to use your understanding of all the three models covered till now. You must select the most robust model and provide a solution that predicts the churn in the most suitable manner. \n",
    "\n",
    "For this assignment, you are provided the data associated with an e-commerce company for the month of October 2019. Your task is to first analyse the data, and then perform multiple steps towards the model building process.\n",
    "\n",
    "The broad tasks are:\n",
    "- Data Exploration\n",
    "- Feature Engineering\n",
    "- Model Selection\n",
    "- Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset stores the information of a customer session on the e-commerce platform. It records the activity and the associated parameters with it.\n",
    "\n",
    "- **event_time**: Date and time when user accesses the platform\n",
    "- **event_type**: Action performed by the customer\n",
    "            - View\n",
    "            - Cart\n",
    "            - Purchase\n",
    "            - Remove from cart\n",
    "- **product_id**: Unique number to identify the product in the event\n",
    "- **category_id**: Unique number to identify the category of the product\n",
    "- **category_code**: Stores primary and secondary categories of the product\n",
    "- **brand**: Brand associated with the product\n",
    "- **price**: Price of the product\n",
    "- **user_id**: Unique ID for a customer\n",
    "- **user_session**: Session ID for a user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provided is 5 GBs in size. Therefore, it is expected that you increase the driver memory to a greater number. You can refer to notebook 1 for the steps involved here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-93-40.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>log_reg</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe901150850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# initialising the session with 14 GB driver memory\n",
    "MAX_MEMORY = \"14G\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"log_reg\") \\\n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.driver.memory = 14G\n"
     ]
    }
   ],
   "source": [
    "print('spark.driver.memory =', spark.sparkContext.getConf().get('spark.driver.memory'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to force only 10% data to be selected from the dataset\n",
    "# This was used only during the initial development of the code\n",
    "# DONOT set this to True and finalize any inference \n",
    "use_small_sample = False\n",
    "load_from_existing_features_dataset = True\n",
    "save_features_dataset=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the clean data\n",
    "if use_small_sample == True:\n",
    "    df= spark.read.parquet(\"cleaned_df.parquet\")\n",
    "    df = df.randomSplit([.05, .95], seed=12)[0]\n",
    "else:\n",
    "    df= spark.read.parquet(\"cleaned_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Model Selection\n",
    "3 models for classification:\t\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional steps for Decision Trees, if any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Transformation (Code will be same; check for the columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat_0_cln',\n",
       " 'price',\n",
       " 'category_level',\n",
       " 'day_of_week',\n",
       " 'cat_1_cln',\n",
       " 'brand_cln',\n",
       " 'session_count',\n",
       " 'activity_count',\n",
       " 'product_view_count',\n",
       " 'second_cat_view_count',\n",
       " 'avg_price',\n",
       " 'hour_bins',\n",
       " 'is_purchased']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if only the required columns are present to build the model\n",
    "# If not, drop the redundant columns\n",
    "df = df.drop('product_id', 'user_id', 'hour')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorising the attributes into its type - Continuous and Categorical\n",
    "numeric_cols = ['price', 'session_count', 'activity_count',\n",
    "                'product_view_count', 'second_cat_view_count',\n",
    "                'avg_price'\n",
    "               ]\n",
    "\n",
    "# List of categorical string columns\n",
    "categorical_str_cols = ['cat_0_cln', 'cat_1_cln', 'brand_cln']\n",
    "\n",
    "# list of categorical numeric columns\n",
    "categorical_num_cols = ['category_level', 'day_of_week', 'hour_bins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features to be given to the moddel =  12\n"
     ]
    }
   ],
   "source": [
    "# Feature transformation for categorical features\n",
    "#\n",
    "stages = []\n",
    "# Creating a pipeline for Feature Transformations\n",
    "# Starting with the categorical string cols\n",
    "for col in categorical_str_cols:\n",
    "    # Encode the strings in the col with an index\n",
    "    indexer = StringIndexer(inputCol=col,\n",
    "                            outputCol = col + '_ix',\n",
    "                           )\n",
    "    # OHE the indices in the col\n",
    "    encoder = OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "                            outputCol=col + '_enc'\n",
    "                           )\n",
    "    stages +=[indexer, encoder]\n",
    "    \n",
    "\n",
    "# Processing thhe Categorical numeric cols\n",
    "for col in categorical_num_cols:\n",
    "    encoder = OneHotEncoder(inputCol=col,\n",
    "                            outputCol=col + '_enc'\n",
    "                           )\n",
    "    stages += [encoder]\n",
    "    \n",
    "# Vector assembler to combine all the features\n",
    "# Add a Vector Assembler to the pipeline stages\n",
    "vector_input_cols = [c + '_enc' for c in categorical_str_cols] + \\\n",
    "                    [c + '_enc' for c in categorical_num_cols] + \\\n",
    "                    numeric_cols\n",
    "print('number of features to be given to the moddel = ', len(vector_input_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[StringIndexer_e7fe2ec1fbb6,\n",
       " OneHotEncoder_11024f76a7da,\n",
       " StringIndexer_f039aaba2f9c,\n",
       " OneHotEncoder_0cb2df844a8b,\n",
       " StringIndexer_fe3a763db57d,\n",
       " OneHotEncoder_97e3c3f7b8f3,\n",
       " OneHotEncoder_b731cc26a33e,\n",
       " OneHotEncoder_1ec78ea3939c,\n",
       " OneHotEncoder_79f37b523c3e,\n",
       " VectorAssembler_5fcfda09e33f]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector assembler to combine all the features\n",
    "vector = VectorAssembler(inputCols = vector_input_cols,\n",
    "                         outputCol = 'features'\n",
    "                        )\n",
    "stages.append(vector)\n",
    "\n",
    "print('stages = ')\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for the tasks\n",
    "pipeline = Pipeline(stages = stages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the dataframe df\n",
    "if load_from_existing_features_dataset == True:\n",
    "    transformed_df = spark.read.parquet('features_df.parquet')\n",
    "else:\n",
    "    pipeline_model = pipeline.fit(df)\n",
    "    transformed_df = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cat_0_cln: string (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      " |-- category_level: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- cat_1_cln: string (nullable = true)\n",
      " |-- brand_cln: string (nullable = true)\n",
      " |-- session_count: long (nullable = true)\n",
      " |-- activity_count: long (nullable = true)\n",
      " |-- product_view_count: long (nullable = true)\n",
      " |-- second_cat_view_count: long (nullable = true)\n",
      " |-- avg_price: double (nullable = true)\n",
      " |-- hour_bins: double (nullable = true)\n",
      " |-- is_purchased: integer (nullable = true)\n",
      " |-- cat_0_cln_ix: double (nullable = true)\n",
      " |-- cat_0_cln_enc: vector (nullable = true)\n",
      " |-- cat_1_cln_ix: double (nullable = true)\n",
      " |-- cat_1_cln_enc: vector (nullable = true)\n",
      " |-- brand_cln_ix: double (nullable = true)\n",
      " |-- brand_cln_enc: vector (nullable = true)\n",
      " |-- category_level_enc: vector (nullable = true)\n",
      " |-- day_of_week_enc: vector (nullable = true)\n",
      " |-- hour_bins_enc: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema of the transformed df\n",
    "transformed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------+-----------+----------+---------+-------------+--------------+------------------+---------------------+-----------------+---------+------------+------------+--------------+------------+--------------+------------+---------------+------------------+---------------+-------------+--------------------+\n",
      "|  cat_0_cln|  price|category_level|day_of_week| cat_1_cln|brand_cln|session_count|activity_count|product_view_count|second_cat_view_count|        avg_price|hour_bins|is_purchased|cat_0_cln_ix| cat_0_cln_enc|cat_1_cln_ix| cat_1_cln_enc|brand_cln_ix|  brand_cln_enc|category_level_enc|day_of_week_enc|hour_bins_enc|            features|\n",
      "+-----------+-------+--------------+-----------+----------+---------+-------------+--------------+------------------+---------------------+-----------------+---------+------------+------------+--------------+------------+--------------+------------+---------------+------------------+---------------+-------------+--------------------+\n",
      "|electronics| 380.28|             2|          1|smartphone|  samsung|            2|             1|                 1|                    1|493.3872257223995|      2.0|           0|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         0.0| (19,[0],[1.0])|     (4,[2],[1.0])|  (7,[1],[1.0])|(3,[2],[1.0])|(91,[0,13,52,73,7...|\n",
      "|electronics| 246.52|             2|          6|smartphone|  samsung|            5|             1|                 3|                    3|493.3872257223995|      2.0|           1|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         0.0| (19,[0],[1.0])|     (4,[2],[1.0])|  (7,[6],[1.0])|(3,[2],[1.0])|(91,[0,13,52,73,8...|\n",
      "|electronics| 389.92|             3|          2|     video|       lg|           10|             1|                 4|                    7|493.3872257223995|      2.0|           0|         0.0|(13,[0],[1.0])|         4.0|(39,[4],[1.0])|         6.0| (19,[6],[1.0])|     (4,[3],[1.0])|  (7,[2],[1.0])|(3,[2],[1.0])|(91,[0,17,58,74,7...|\n",
      "|electronics|1671.34|             2|          1|smartphone|    apple|            9|             1|                 9|                   18|493.3872257223995|      2.0|           0|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         1.0| (19,[1],[1.0])|     (4,[2],[1.0])|  (7,[1],[1.0])|(3,[2],[1.0])|(91,[0,13,53,73,7...|\n",
      "|electronics| 131.64|             2|          4|smartphone|  samsung|            3|             1|                 3|                    3|493.3872257223995|      1.0|           0|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         0.0| (19,[0],[1.0])|     (4,[2],[1.0])|  (7,[4],[1.0])|(3,[1],[1.0])|(91,[0,13,52,73,7...|\n",
      "|electronics| 230.79|             2|          1|smartphone|   xiaomi|           16|             3|                19|                   90|493.3872257223995|      2.0|           0|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         3.0| (19,[3],[1.0])|     (4,[2],[1.0])|  (7,[1],[1.0])|(3,[2],[1.0])|(91,[0,13,55,73,7...|\n",
      "|electronics| 230.79|             2|          1|smartphone|   xiaomi|           16|             3|                19|                   90|493.3872257223995|      2.0|           0|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         3.0| (19,[3],[1.0])|     (4,[2],[1.0])|  (7,[1],[1.0])|(3,[2],[1.0])|(91,[0,13,55,73,7...|\n",
      "|electronics| 230.79|             2|          1|smartphone|   xiaomi|           16|             3|                19|                   90|493.3872257223995|      2.0|           0|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         3.0| (19,[3],[1.0])|     (4,[2],[1.0])|  (7,[1],[1.0])|(3,[2],[1.0])|(91,[0,13,55,73,7...|\n",
      "|electronics|  98.28|             2|          7|smartphone|   xiaomi|           11|             2|                 5|                   21|493.3872257223995|      1.0|           0|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         3.0| (19,[3],[1.0])|     (4,[2],[1.0])|      (7,[],[])|(3,[1],[1.0])|(91,[0,13,55,73,8...|\n",
      "|electronics| 102.94|             3|          3|     audio|   huawei|            6|             2|                12|                   14|493.3872257223995|      0.0|           1|         0.0|(13,[0],[1.0])|         3.0|(39,[3],[1.0])|         4.0| (19,[4],[1.0])|     (4,[3],[1.0])|  (7,[3],[1.0])|(3,[0],[1.0])|(91,[0,16,56,74,7...|\n",
      "|electronics| 102.94|             3|          3|     audio|   huawei|            6|             2|                12|                   14|493.3872257223995|      0.0|           1|         0.0|(13,[0],[1.0])|         3.0|(39,[3],[1.0])|         4.0| (19,[4],[1.0])|     (4,[3],[1.0])|  (7,[3],[1.0])|(3,[0],[1.0])|(91,[0,16,56,74,7...|\n",
      "|electronics| 197.15|             2|          6|smartphone|   xiaomi|            7|             2|                 7|                   35|493.3872257223995|      0.0|           1|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         3.0| (19,[3],[1.0])|     (4,[2],[1.0])|  (7,[6],[1.0])|(3,[0],[1.0])|(91,[0,13,55,73,8...|\n",
      "|electronics| 197.15|             2|          6|smartphone|   xiaomi|            7|             2|                 7|                   35|493.3872257223995|      0.0|           1|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         3.0| (19,[3],[1.0])|     (4,[2],[1.0])|  (7,[6],[1.0])|(3,[0],[1.0])|(91,[0,13,55,73,8...|\n",
      "|electronics| 756.65|             2|          5|smartphone|    apple|           17|             3|                 2|                   32|493.3872257223995|      1.0|           1|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         1.0| (19,[1],[1.0])|     (4,[2],[1.0])|  (7,[5],[1.0])|(3,[1],[1.0])|(91,[0,13,53,73,8...|\n",
      "|electronics| 756.65|             2|          5|smartphone|    apple|           17|             3|                 2|                   32|493.3872257223995|      1.0|           1|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         1.0| (19,[1],[1.0])|     (4,[2],[1.0])|  (7,[5],[1.0])|(3,[1],[1.0])|(91,[0,13,53,73,8...|\n",
      "|      Blank|  30.35|             0|          7|     Blank|  samsung|            7|             2|                10|                   20|226.9555916574436|      2.0|           1|         1.0|(13,[1],[1.0])|         1.0|(39,[1],[1.0])|         0.0| (19,[0],[1.0])|     (4,[0],[1.0])|      (7,[],[])|(3,[2],[1.0])|(91,[1,14,52,71,8...|\n",
      "|      Blank|  30.35|             0|          7|     Blank|  samsung|            7|             2|                10|                   20|226.9555916574436|      2.0|           1|         1.0|(13,[1],[1.0])|         1.0|(39,[1],[1.0])|         0.0| (19,[0],[1.0])|     (4,[0],[1.0])|      (7,[],[])|(3,[2],[1.0])|(91,[1,14,52,71,8...|\n",
      "|      Blank|  78.15|             0|          3|     Blank|    bosch|           14|             2|                 5|                  180|226.9555916574436|      3.0|           1|         1.0|(13,[1],[1.0])|         1.0|(39,[1],[1.0])|        10.0|(19,[10],[1.0])|     (4,[0],[1.0])|  (7,[3],[1.0])|    (3,[],[])|(91,[1,14,62,71,7...|\n",
      "|electronics| 804.37|             2|          7|smartphone|    apple|            8|             2|                 3|                   33|493.3872257223995|      1.0|           0|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         1.0| (19,[1],[1.0])|     (4,[2],[1.0])|      (7,[],[])|(3,[1],[1.0])|(91,[0,13,53,73,8...|\n",
      "|electronics|   77.2|             2|          3|smartphone|   others|           17|             3|                 4|                   55|493.3872257223995|      0.0|           0|         0.0|(13,[0],[1.0])|         0.0|(39,[0],[1.0])|         2.0| (19,[2],[1.0])|     (4,[2],[1.0])|  (7,[3],[1.0])|(3,[0],[1.0])|(91,[0,13,54,73,7...|\n",
      "+-----------+-------+--------------+-----------+----------+---------+-------------+--------------+------------------+---------------------+-----------------+---------+------------+------------+--------------+------------+--------------+------------+---------------+------------------+---------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the elements of the transformed df - Top 20 rows\n",
    "transformed_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the transformed df in S3 bucket to prevent repetition of steps again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming the target column as label as a workaround for crossValidator to run without error\n",
    "transformed_df = transformed_df.withColumnRenamed('is_purchased', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test (Remember you are expected to compare the model later)\n",
    "train, test = transformed_df.randomSplit([0.8, 0.2], seed=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train data = 718925\n",
      "Number of rows in test data = 179516\n"
     ]
    }
   ],
   "source": [
    "# Number of rows in train and test data\n",
    "print(f'Number of rows in train data = {train.count()}')\n",
    "print(f'Number of rows in test data = {test.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model with hyperparameter tuning\n",
    "# Create ParamGrid for Cross Validation\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "grid = ParamGridBuilder()\\\n",
    "        .baseOn({tree.featuresCol: 'features'})\\\n",
    "        .baseOn({tree.labelCol: 'label'})\\\n",
    "        .baseOn({tree.seed: 12})\\\n",
    "        .addGrid(tree.maxDepth, [3, 4, 5, 6, 7])\\\n",
    "        .addGrid(tree.minInstancesPerNode, [5, 10, 20, 50, 100])\\\n",
    "        .addGrid(tree.maxBins, [5, 20, 30, 50])\\\n",
    "        .addGrid(tree.impurity, ['gini', 'entropy'])\\\n",
    "        .build()\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label',\n",
    "                                          metricName='areaUnderPR')\n",
    "# evaluator = MulticlassClassificationEvaluator(labelCol = 'label',\n",
    "#                                               metricName='recallByLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation steps\n",
    "cv = CrossValidator(estimator=tree, \n",
    "                    estimatorParamMaps=grid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds = 3,\n",
    "                    seed = 12\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the models on transformed df\n",
    "cvModel = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_b84abb6e14f1) of depth 7 with 113 nodes"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree = cvModel.bestModel\n",
    "best_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Steps:\n",
    "- Fit on test data\n",
    "- Performance analysis\n",
    "    - Appropriate Metric with reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions for the test data\n",
    "\n",
    "predictions = best_tree.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+--------------+-----------+---------+---------+-------------+--------------+------------------+---------------------+-----------------+---------+-----+------------+--------------+------------+--------------+------------+--------------+------------------+---------------+-------------+--------------------+---------------+--------------------+----------+\n",
      "|cat_0_cln|price|category_level|day_of_week|cat_1_cln|brand_cln|session_count|activity_count|product_view_count|second_cat_view_count|        avg_price|hour_bins|label|cat_0_cln_ix| cat_0_cln_enc|cat_1_cln_ix| cat_1_cln_enc|brand_cln_ix| brand_cln_enc|category_level_enc|day_of_week_enc|hour_bins_enc|            features|  rawPrediction|         probability|prediction|\n",
      "+---------+-----+--------------+-----------+---------+---------+-------------+--------------+------------------+---------------------+-----------------+---------+-----+------------+--------------+------------+--------------+------------+--------------+------------------+---------------+-------------+--------------------+---------------+--------------------+----------+\n",
      "|    Blank|  0.0|             0|          2|    Blank|   others|            4|             1|                 7|                   58|226.9555916574436|      1.0|    1|         1.0|(13,[1],[1.0])|         1.0|(39,[1],[1.0])|         2.0|(19,[2],[1.0])|     (4,[0],[1.0])|  (7,[2],[1.0])|(3,[1],[1.0])|(91,[1,14,54,71,7...| [736.0,1050.0]|[0.41209406494960...|       1.0|\n",
      "|    Blank|  0.0|             0|          2|    Blank|   others|           12|             3|                 2|                    3|226.9555916574436|      1.0|    0|         1.0|(13,[1],[1.0])|         1.0|(39,[1],[1.0])|         2.0|(19,[2],[1.0])|     (4,[0],[1.0])|  (7,[2],[1.0])|(3,[1],[1.0])|(91,[1,14,54,71,7...|[4338.0,3563.0]|[0.54904442475636...|       0.0|\n",
      "+---------+-----+--------------+-----------+---------+---------+-------------+--------------+------------------+---------------------+-----------------+---------+-----+------------+--------------+------------+--------------+------------+--------------+------------------+---------------+-------------+--------------------+---------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       1.0|  1.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  1.0|\n",
      "+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_and_labels=predictions.select(['prediction','label'])\n",
    "preds_and_labels = preds_and_labels.withColumn('label', preds_and_labels['label'].cast(FloatType()))\n",
    "preds_and_labels.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prediction', 'double'), ('label', 'float')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_and_labels.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25262. 45254.]\n",
      " [16482. 92518.]]\n"
     ]
    }
   ],
   "source": [
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for label 1 =  0.6560975066289356\n",
      "Precision for label 1 = 0.6715297738292251\n",
      "Recall for label 1 = 0.848788990825688\n",
      "F1 score =  0.7498257500850987\n"
     ]
    }
   ],
   "source": [
    "# accuracy for label 1\n",
    "print('Accuracy for label 1 = ', metrics.accuracy)\n",
    "#precision for label 1\n",
    "print('Precision for label 1 =', metrics.precision(1))\n",
    "\n",
    "#recall for label 1\n",
    "print('Recall for label 1 =', metrics.recall(1))\n",
    "\n",
    "#F1 score for label 1\n",
    "print('F1 score = ', metrics.fMeasure(1.0, beta = 1.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve =  0.6035169640724389\n"
     ]
    }
   ],
   "source": [
    "binary_metrics = BinaryClassificationMetrics(preds_and_labels.rdd.map(tuple))\n",
    "\n",
    "print('Area Under Curve = ', binary_metrics.areaUnderROC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the best Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(91, {13: 0.1303, 18: 0.0002, 52: 0.0116, 53: 0.0014, 55: 0.0106, 78: 0.0002, 80: 0.0004, 83: 0.0007, 85: 0.002, 86: 0.2082, 87: 0.083, 88: 0.482, 89: 0.0694})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DecisionTreeClassificationModel (uid=DecisionTreeClassifier_b84abb6e14f1) of depth 7 with 113 nodes\\n  If (feature 88 <= 6.5)\\n   If (feature 86 <= 3.5)\\n    If (feature 88 <= 2.5)\\n     If (feature 87 <= 1.5)\\n      If (feature 52 in {1.0})\\n       If (feature 13 in {0.0})\\n        Predict: 0.0\\n       Else (feature 13 not in {0.0})\\n        If (feature 89 <= 11.5)\\n         Predict: 0.0\\n        Else (feature 89 > 11.5)\\n         Predict: 1.0\\n      Else (feature 52 not in {1.0})\\n       Predict: 0.0\\n     Else (feature 87 > 1.5)\\n      Predict: 0.0\\n    Else (feature 88 > 2.5)\\n     If (feature 52 in {1.0})\\n      If (feature 88 <= 3.5)\\n       If (feature 85 <= 251.1050033569336)\\n        If (feature 87 <= 1.5)\\n         Predict: 1.0\\n        Else (feature 87 > 1.5)\\n         Predict: 0.0\\n       Else (feature 85 > 251.1050033569336)\\n        If (feature 83 in {0.0})\\n         Predict: 0.0\\n        Else (feature 83 not in {0.0})\\n         Predict: 1.0\\n      Else (feature 88 > 3.5)\\n       If (feature 13 in {0.0})\\n        If (feature 18 in {1.0})\\n         Predict: 1.0\\n        Else (feature 18 not in {1.0})\\n         Predict: 0.0\\n       Else (feature 13 not in {0.0})\\n        If (feature 87 <= 1.5)\\n         Predict: 1.0\\n        Else (feature 87 > 1.5)\\n         Predict: 0.0\\n     Else (feature 52 not in {1.0})\\n      If (feature 88 <= 3.5)\\n       Predict: 0.0\\n      Else (feature 88 > 3.5)\\n       If (feature 87 <= 1.5)\\n        If (feature 83 in {1.0})\\n         Predict: 1.0\\n        Else (feature 83 not in {1.0})\\n         Predict: 0.0\\n       Else (feature 87 > 1.5)\\n        Predict: 0.0\\n   Else (feature 86 > 3.5)\\n    If (feature 13 in {0.0})\\n     If (feature 89 <= 11.5)\\n      If (feature 87 <= 1.5)\\n       If (feature 86 <= 5.5)\\n        Predict: 1.0\\n       Else (feature 86 > 5.5)\\n        Predict: 0.0\\n      Else (feature 87 > 1.5)\\n       If (feature 88 <= 2.5)\\n        If (feature 87 <= 2.5)\\n         Predict: 1.0\\n        Else (feature 87 > 2.5)\\n         Predict: 0.0\\n       Else (feature 88 > 2.5)\\n        Predict: 1.0\\n     Else (feature 89 > 11.5)\\n      If (feature 86 <= 8.5)\\n       If (feature 88 <= 3.5)\\n        Predict: 0.0\\n       Else (feature 88 > 3.5)\\n        Predict: 1.0\\n      Else (feature 86 > 8.5)\\n       Predict: 0.0\\n    Else (feature 13 not in {0.0})\\n     If (feature 86 <= 14.5)\\n      If (feature 89 <= 5.5)\\n       If (feature 86 <= 5.5)\\n        If (feature 87 <= 2.5)\\n         Predict: 1.0\\n        Else (feature 87 > 2.5)\\n         Predict: 0.0\\n       Else (feature 86 > 5.5)\\n        Predict: 1.0\\n      Else (feature 89 > 5.5)\\n       Predict: 1.0\\n     Else (feature 86 > 14.5)\\n      If (feature 87 <= 1.5)\\n       Predict: 0.0\\n      Else (feature 87 > 1.5)\\n       If (feature 88 <= 2.5)\\n        Predict: 0.0\\n       Else (feature 88 > 2.5)\\n        Predict: 1.0\\n  Else (feature 88 > 6.5)\\n   If (feature 88 <= 11.5)\\n    If (feature 89 <= 44.5)\\n     If (feature 13 in {0.0})\\n      If (feature 87 <= 1.5)\\n       If (feature 86 <= 8.5)\\n        Predict: 1.0\\n       Else (feature 86 > 8.5)\\n        Predict: 0.0\\n      Else (feature 87 > 1.5)\\n       Predict: 1.0\\n     Else (feature 13 not in {0.0})\\n      Predict: 1.0\\n    Else (feature 89 > 44.5)\\n     If (feature 86 <= 14.5)\\n      If (feature 13 in {0.0})\\n       If (feature 87 <= 1.5)\\n        If (feature 86 <= 5.5)\\n         Predict: 1.0\\n        Else (feature 86 > 5.5)\\n         Predict: 0.0\\n       Else (feature 87 > 1.5)\\n        Predict: 1.0\\n      Else (feature 13 not in {0.0})\\n       If (feature 55 in {1.0})\\n        If (feature 85 <= 251.1050033569336)\\n         Predict: 1.0\\n        Else (feature 85 > 251.1050033569336)\\n         Predict: 0.0\\n       Else (feature 55 not in {1.0})\\n        Predict: 1.0\\n     Else (feature 86 > 14.5)\\n      If (feature 87 <= 1.5)\\n       Predict: 0.0\\n      Else (feature 87 > 1.5)\\n       If (feature 53 in {1.0})\\n        If (feature 80 in {1.0})\\n         Predict: 0.0\\n        Else (feature 80 not in {1.0})\\n         Predict: 1.0\\n       Else (feature 53 not in {1.0})\\n        If (feature 52 in {1.0})\\n         Predict: 1.0\\n        Else (feature 52 not in {1.0})\\n         Predict: 0.0\\n   Else (feature 88 > 11.5)\\n    If (feature 86 <= 14.5)\\n     If (feature 55 in {1.0})\\n      If (feature 85 <= 251.1050033569336)\\n       Predict: 1.0\\n      Else (feature 85 > 251.1050033569336)\\n       If (feature 78 in {1.0})\\n        If (feature 83 in {1.0})\\n         Predict: 0.0\\n        Else (feature 83 not in {1.0})\\n         Predict: 1.0\\n       Else (feature 78 not in {1.0})\\n        Predict: 1.0\\n     Else (feature 55 not in {1.0})\\n      Predict: 1.0\\n    Else (feature 86 > 14.5)\\n     If (feature 87 <= 2.5)\\n      If (feature 87 <= 1.5)\\n       If (feature 89 <= 44.5)\\n        Predict: 1.0\\n       Else (feature 89 > 44.5)\\n        If (feature 53 in {1.0})\\n         Predict: 1.0\\n        Else (feature 53 not in {1.0})\\n         Predict: 0.0\\n      Else (feature 87 > 1.5)\\n       Predict: 1.0\\n     Else (feature 87 > 2.5)\\n      Predict: 1.0\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree.toDebugString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "    best_tree.save('decision_tree_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
